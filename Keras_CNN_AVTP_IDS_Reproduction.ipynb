{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mount google drive"
      ],
      "metadata": {
        "id": "tloeYj8aN6PT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3PRSn09CHgB",
        "outputId": "58f4d850-727a-4e18-9575-a92823d1a70b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "hTt-SkNYODxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library\n",
        "!pip install scapy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYrLAhDDOHqF",
        "outputId": "1cdcd80a-f886-4ada-870b-d28edffedb09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scapy in /usr/local/lib/python3.7/dist-packages (2.4.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "qQm0ItLhN-0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "\n",
        "import gc # garbage collector\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scapy.all import *\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras import regularizersdr\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "GNdh8r9UN-Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filepaths"
      ],
      "metadata": {
        "id": "Fhb0TmyMN8zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive_root_path = \"/content/drive/MyDrive/AVTP dataset\"\n",
        "\n",
        "# Indoors original\n",
        "indoors_01_original_fp = f\"{drive_root_path}/indoors_01_original.pcap\"\n",
        "indoors_02_original_fp = f\"{drive_root_path}/indoors_02_original.pcap\"\n",
        "\n",
        "# Indoors injected\n",
        "indoors_01_injected_fp = f\"{drive_root_path}/indoors_01_injected.pcap\"\n",
        "indoors_02_injected_fp = f\"{drive_root_path}/indoors_02_injected.pcap\"\n",
        "\n",
        "# Driving\n",
        "driving_01_injected_fp = f\"{drive_root_path}/driving_01_injected.pcap\"\n",
        "driving_02_injected_fp = f\"{drive_root_path}/driving_02_injected.pcap\"\n",
        "\n",
        "# Injected only\n",
        "single_MPEG_frame_fp = f\"{drive_root_path}/single-MPEG-frame.pcap\""
      ],
      "metadata": {
        "id": "F9A_O1vwCV33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper functions"
      ],
      "metadata": {
        "id": "2fRs3G3uOf5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "def __read_raw_packets(pcap_filepath):\n",
        "  raw_packets = rdpcap(pcap_filepath)\n",
        "\n",
        "  raw_packets_list = []\n",
        "\n",
        "  for packet in raw_packets:\n",
        "    if (len(packet) == 438): # The length of AVTP packets in 438 bytes\n",
        "      raw_packets_list.append(raw(packet))\n",
        "\n",
        "  return raw_packets_list\n",
        "\n",
        "\n",
        "def __convert_raw_packets(raw_packets_list):\n",
        "  converted_packets_list = []\n",
        "\n",
        "  for raw_packet in raw_packets_list:\n",
        "    converted_packet = np.frombuffer(raw_packet, dtype='uint8')\n",
        "    converted_packets_list.append(converted_packet)\n",
        "\n",
        "  return np.array(converted_packets_list, dtype='uint8')\n",
        "\n",
        "\n",
        "def __is_array_in_list_of_arrays(array_to_check, list_np_arrays):\n",
        "  # Reference:\n",
        "  # https://stackoverflow.com/questions/23979146/check-if-numpy-array-is-in-list-of-numpy-arrays\n",
        "  is_in_list = np.any(np.all(array_to_check == list_np_arrays, axis=1))\n",
        "\n",
        "  return is_in_list\n",
        "\n",
        "\n",
        "def __generate_labels(packets_list, injected_packets):\n",
        "  labels_list = []\n",
        "\n",
        "  for packet in packets_list:\n",
        "    current_label = 0\n",
        "\n",
        "    if __is_array_in_list_of_arrays(packet, injected_packets):\n",
        "      current_label = 1\n",
        "\n",
        "    labels_list.append(current_label)\n",
        "\n",
        "  return labels_list\n",
        "\n",
        "\n",
        "def __select_packets_bytes(packets_list, first_byte=0, last_byte=58):\n",
        "  selected_packets = packets_list[:, first_byte:last_byte]\n",
        "\n",
        "  return np.array(selected_packets, dtype='uint8')\n",
        "\n",
        "\n",
        "def __calculate_difference_module(selected_packets):\n",
        "  difference_array = np.diff(selected_packets, axis=0)\n",
        "  difference_module = np.mod(difference_array, 256)\n",
        "\n",
        "  return difference_module\n",
        "\n",
        "\n",
        "def __split_byte_into_nibbles(byte):\n",
        "  high_nibble = (byte >> 4) & 0xf\n",
        "  low_nibble = (byte) & 0xf\n",
        "\n",
        "  return high_nibble, low_nibble\n",
        "\n",
        "\n",
        "def __create_nibbles_matrix(difference_module):\n",
        "  nibbles_matrix = []\n",
        "\n",
        "  # difference matrix Ã© uma matriz com n linhas e p colunas\n",
        "  for row_index in range(len(difference_module)):\n",
        "    nibbles_row = []\n",
        "    for column_index in range(len(difference_module[row_index])):\n",
        "      hi_ni, low_ni = __split_byte_into_nibbles(difference_module[row_index, column_index])\n",
        "\n",
        "      nibbles_row.append(hi_ni)\n",
        "      nibbles_row.append(low_ni)\n",
        "\n",
        "    nibbles_matrix.append(np.array(nibbles_row, dtype='uint8'))\n",
        "\n",
        "  return np.array(nibbles_matrix, dtype='uint8')\n",
        "\n",
        "\n",
        "def aggregate_based_on_window_size(x_data, y_data, window_size=44, window_slide=44):\n",
        "    # Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "\n",
        "    # Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        start_ix = i*(window_slide)\n",
        "        end_ix = start_ix + window_size - 1 + 1\n",
        "\n",
        "        # if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "\n",
        "        # Get a sequence of data for x\n",
        "        seq_X = x_data[start_ix:end_ix]\n",
        "        if (window_slide == 1):\n",
        "          # Get only the last element of the sequence for y\n",
        "          seq_y = y_data[end_ix]\n",
        "        else:\n",
        "          # If the sequence contains an attack, the label is considered as attack\n",
        "          tmp_seq_y = y_data[start_ix:end_ix]\n",
        "          if 1 in tmp_seq_y:\n",
        "            seq_y = 1\n",
        "          else:\n",
        "            seq_y = 0\n",
        "        # Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "    # Make final arrays\n",
        "    x_array = np.array(X, dtype='uint8')\n",
        "    y_array = np.array(y, dtype='uint8')\n",
        "\n",
        "    return x_array, y_array\n",
        "\n",
        "\n",
        "def __map_model_predictions(predictions, threshold=0.5):\n",
        "\n",
        "  predictions_true = predictions > threshold\n",
        "  predictions_false = predictions <= threshold\n",
        "\n",
        "  predictions[predictions_true] = 1\n",
        "  predictions[predictions_false] = 0\n",
        "\n",
        "  return predictions\n",
        "\n",
        "\n",
        "def __create_model():\n",
        "  model = models.Sequential()\n",
        "  # Input layer\n",
        "  model.add(keras.Input(shape=(44, 116, 1)))\n",
        "\n",
        "  # Feature extraction layers\n",
        "  model.add(layers.Conv2D(32, (5, 5), strides=(1,1), padding=\"same\", activation=\"relu\", kernel_regularizer='l2'))\n",
        "  model.add(layers.BatchNormalization(momentum=0.99, epsilon=0.001))\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(layers.Conv2D(64, (5, 5), strides=(1,1), padding=\"same\", activation=\"relu\", kernel_regularizer='l2'))\n",
        "  model.add(layers.BatchNormalization(momentum=0.99, epsilon=0.001))\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # Binary classification\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Dense(units=64, activation=\"relu\"))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "  # Optimizer and compile\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model.compile(\n",
        "              loss=\"binary_crossentropy\",\n",
        "              optimizer=opt,\n",
        "              metrics=[\n",
        "                       tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\")]\n",
        "              )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "3Pf7BrTTDw_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature generator and constructing labeled dataset"
      ],
      "metadata": {
        "id": "EORCNIgrO5IZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load raw packets"
      ],
      "metadata": {
        "id": "gdLxUcS1YiZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Injected\n",
        "raw_indoors_01_injected_packets_list = __read_raw_packets(indoors_01_injected_fp)\n",
        "raw_indoors_02_injected_packets_list = __read_raw_packets(indoors_02_injected_fp)\n",
        "\n",
        "# Original\n",
        "# raw_indoors_01_original_packets_list = __read_raw_packets(indoors_01_original_fp)\n",
        "# raw_indoors_02_original_packets_list = __read_raw_packets(indoors_02_original_fp)\n",
        "\n",
        "# Injected (36)\n",
        "raw_injected_packets_list = __read_raw_packets(single_MPEG_frame_fp)"
      ],
      "metadata": {
        "id": "vU5mEUjKYh8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert and apply feature generator"
      ],
      "metadata": {
        "id": "tMC3JAiMExpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get raw packets from .pcap files\n",
        "# Primeiro Ã© bastante custoso\n",
        "\n",
        "# Convert packets\n",
        "## Injected\n",
        "converted_indoors_01_injected_packets_list = __convert_raw_packets(raw_indoors_01_injected_packets_list)\n",
        "converted_indoors_02_injected_packets_list = __convert_raw_packets(raw_indoors_02_injected_packets_list)\n",
        "\n",
        "# Merged converted packets\n",
        "# merged_indoors_injected_packets = np.concatenate((converted_indoors_01_injected_packets_list, converted_indoors_02_injected_packets_list), axis=0)\n",
        "\n",
        "## Injected(36)\n",
        "converted_injected_packets = __convert_raw_packets(raw_injected_packets_list)\n",
        "\n",
        "# Generate labels\n",
        "y_indoors_01_injected = __generate_labels(converted_indoors_01_injected_packets_list, converted_injected_packets)\n",
        "y_indoors_02_injected = __generate_labels(converted_indoors_02_injected_packets_list, converted_injected_packets)\n",
        "\n",
        "# Select first 58 bytes\n",
        "selected_indoor_01_injected_packets = __select_packets_bytes(converted_indoors_01_injected_packets_list)\n",
        "selected_indoor_02_injected_packets = __select_packets_bytes(converted_indoors_02_injected_packets_list)\n",
        "\n",
        "# Calculate difference and module between rows\n",
        "diff_module_indoor_01_injected_packets = __calculate_difference_module(selected_indoor_01_injected_packets)\n",
        "diff_module_indoor_02_injected_packets = __calculate_difference_module(selected_indoor_02_injected_packets)\n",
        "\n",
        "# Split difference into two nibbles\n",
        "nibbles_indoors_01_injected_packets = __create_nibbles_matrix(diff_module_indoor_01_injected_packets)\n",
        "nibbles_indoors_02_injected_packets = __create_nibbles_matrix(diff_module_indoor_02_injected_packets)\n",
        "\n",
        "# Aggregate features and labels based on window size\n",
        "X_indoors_01_injected_agg, y_indoors_01_injected_agg = aggregate_based_on_window_size(nibbles_indoors_01_injected_packets, y_indoors_01_injected, window_size=44, window_slide=1)\n",
        "X_indoors_02_injected_agg, y_indoors_02_injected_agg = aggregate_based_on_window_size(nibbles_indoors_02_injected_packets, y_indoors_02_injected, window_size=44, window_slide=1)\n",
        "\n",
        "X_indoors_injected_agg = np.concatenate((X_indoors_01_injected_agg, X_indoors_02_injected_agg), axis=0)\n",
        "y_indoors_injected_agg = np.concatenate((y_indoors_01_injected_agg, y_indoors_02_injected_agg), axis=0)"
      ],
      "metadata": {
        "id": "xGzQUrrpuOmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete unused variables\n",
        "del raw_indoors_01_injected_packets_list\n",
        "del raw_indoors_02_injected_packets_list\n",
        "\n",
        "del raw_injected_packets_list\n",
        "\n",
        "del converted_indoors_01_injected_packets_list\n",
        "del converted_indoors_02_injected_packets_list\n",
        "\n",
        "del converted_injected_packets\n",
        "\n",
        "del y_indoors_01_injected\n",
        "del y_indoors_02_injected\n",
        "\n",
        "del selected_indoor_01_injected_packets\n",
        "del selected_indoor_02_injected_packets\n",
        "\n",
        "del diff_module_indoor_01_injected_packets\n",
        "del diff_module_indoor_02_injected_packets\n",
        "\n",
        "del nibbles_indoors_01_injected_packets\n",
        "del nibbles_indoors_02_injected_packets\n",
        "\n",
        "del X_indoors_01_injected_agg\n",
        "del y_indoors_01_injected_agg\n",
        "\n",
        "del X_indoors_02_injected_agg\n",
        "del y_indoors_02_injected_agg"
      ],
      "metadata": {
        "id": "3CGeuRZ-iI0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if dataset was properly labeled\n",
        "\n",
        "indoors_unique, indoors_counts = np.unique(np.array(y_indoors_injected_agg), return_counts=True)\n",
        "\n",
        "# Dindoors has 446,372 bening Xis and 196,894 injected Xis [Paper information]\n",
        "print(f\"Dindoors has {indoors_counts[0]} bening Xis and {indoors_counts[1]} injected Xis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u71LbR1ImNOr",
        "outputId": "5118dfd2-0c74-4709-a076-82b8cb865929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dindoors has 446372 bening Xis and 196892 injected Xis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create model"
      ],
      "metadata": {
        "id": "bQSviLpzE0U2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_indoors_injected_agg.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SS2C95AJJ1N",
        "outputId": "e4092e96-6dd4-40a8-c564-99e5308ce132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(643264, 44, 116)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_seeds():\n",
        "    np.random.seed(1)\n",
        "    random.seed(2)\n",
        "    if tf.__version__[0] == '2':\n",
        "        tf.random.set_seed(3)\n",
        "    else:\n",
        "        tf.set_random_seed(3)\n",
        "    print(\"RANDOM SEEDS RESET\")"
      ],
      "metadata": {
        "id": "wUHxHngYnKfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In each cross-validation, 80% and 20% of the samples\n",
        "# are randomly selected as the training and validation sets, respectively.\n",
        "# We randomly assigned 80% of Xis to the trining set\n",
        "# and 20% of Xis to the test set for each Dindoors\n",
        "skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
        "\n",
        "metrics_list = []\n",
        "fold_number = 1\n",
        "\n",
        "for train_index, val_index in skf.split(X_indoors_injected_agg, y_indoors_injected_agg):\n",
        "  print(f\"Fold atual = {fold_number}\")\n",
        "  X_train, X_val = X_indoors_injected_agg[train_index], X_indoors_injected_agg[val_index]\n",
        "  y_train, y_val = y_indoors_injected_agg[train_index], y_indoors_injected_agg[val_index]\n",
        "\n",
        "  reset_seeds()\n",
        "  model = __create_model()\n",
        "  print(model.summary())\n",
        "\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(f\"{drive_root_path}/model_{fold_number}.h5\",\n",
        "                                                monitor='binary_accuracy', verbose=0,\n",
        "                                                save_best_only=True, mode='max')\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",\n",
        "                                                      patience=5,\n",
        "                                                      verbose=1)\n",
        "  callbacks_list = [early_stopping,\n",
        "                    checkpoint]\n",
        "\n",
        "  model.fit(X_train, y_train,\n",
        "                      batch_size=64,\n",
        "                      epochs=30,\n",
        "                      callbacks=callbacks_list)\n",
        "\n",
        "  # Run predictions on validation set\n",
        "  probability_predictions = model.predict(X_val)\n",
        "  y_pred = __map_model_predictions(probability_predictions)\n",
        "\n",
        "  # Calculate metrics\n",
        "  acc = accuracy_score(y_val, y_pred)\n",
        "  prec = precision_score(y_val, y_pred)\n",
        "  recall = recall_score(y_val, y_pred)\n",
        "  f1 = f1_score(y_val, y_pred)\n",
        "  roc_auc = roc_auc_score(y_val, y_pred)\n",
        "\n",
        "  # Append metrics on list\n",
        "  metrics_list.append([fold_number, acc, prec, recall, f1, roc_auc])\n",
        "  metrics_df = pd.DataFrame(metrics_list, columns=[\"fold\", \"acc\", \"prec\", \"recall\", \"f1\", \"roc_auc\"])\n",
        "  metrics_df.to_csv(f\"{drive_root_path}/models_metrics.csv\")\n",
        "\n",
        "  fold_number = fold_number + 1\n",
        "\n",
        "  del model\n",
        "  del probability_predictions\n",
        "  del y_pred\n",
        "  del X_train, X_val\n",
        "  del y_train, y_val\n",
        "  gc.collect()\n",
        "  tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efjwlgabIAn5",
        "outputId": "3543e123-7859-4c23-a9f7-98d24ee4d8aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold atual = 1\n",
            "RANDOM SEEDS RESET\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 44, 116, 32)       832       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 44, 116, 32)      128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 22, 58, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 22, 58, 64)        51264     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 22, 58, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 11, 29, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 20416)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20416)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1306688   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,359,233\n",
            "Trainable params: 1,359,041\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.1848 - binary_accuracy: 0.9521\n",
            "Epoch 2/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.1011 - binary_accuracy: 0.9782\n",
            "Epoch 3/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0830 - binary_accuracy: 0.9828\n",
            "Epoch 4/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0745 - binary_accuracy: 0.9844\n",
            "Epoch 5/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0694 - binary_accuracy: 0.9855\n",
            "Epoch 6/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0649 - binary_accuracy: 0.9866\n",
            "Epoch 7/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0634 - binary_accuracy: 0.9868\n",
            "Epoch 8/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0602 - binary_accuracy: 0.9878\n",
            "Epoch 9/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0584 - binary_accuracy: 0.9880\n",
            "Epoch 10/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0573 - binary_accuracy: 0.9883\n",
            "Epoch 11/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0563 - binary_accuracy: 0.9890\n",
            "Epoch 12/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0548 - binary_accuracy: 0.9892\n",
            "Epoch 13/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0538 - binary_accuracy: 0.9895\n",
            "Epoch 14/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0533 - binary_accuracy: 0.9899\n",
            "Epoch 15/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0529 - binary_accuracy: 0.9901\n",
            "Epoch 16/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0521 - binary_accuracy: 0.9901\n",
            "Epoch 17/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0510 - binary_accuracy: 0.9904\n",
            "Epoch 18/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0509 - binary_accuracy: 0.9906\n",
            "Epoch 19/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0507 - binary_accuracy: 0.9905\n",
            "Epoch 20/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0496 - binary_accuracy: 0.9906\n",
            "Epoch 21/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0494 - binary_accuracy: 0.9908\n",
            "Epoch 22/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0488 - binary_accuracy: 0.9910\n",
            "Epoch 23/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0485 - binary_accuracy: 0.9910\n",
            "Epoch 24/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0478 - binary_accuracy: 0.9912\n",
            "Epoch 25/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0481 - binary_accuracy: 0.9911\n",
            "Epoch 26/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0476 - binary_accuracy: 0.9911\n",
            "Epoch 27/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0479 - binary_accuracy: 0.9912\n",
            "Epoch 28/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0478 - binary_accuracy: 0.9912\n",
            "Epoch 29/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0468 - binary_accuracy: 0.9912\n",
            "Epoch 30/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0467 - binary_accuracy: 0.9915\n",
            "Fold atual = 2\n",
            "RANDOM SEEDS RESET\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 44, 116, 32)       832       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 44, 116, 32)      128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 22, 58, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 22, 58, 64)        51264     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 22, 58, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 11, 29, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 20416)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20416)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1306688   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,359,233\n",
            "Trainable params: 1,359,041\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.1871 - binary_accuracy: 0.9494\n",
            "Epoch 2/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.1112 - binary_accuracy: 0.9734\n",
            "Epoch 3/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0903 - binary_accuracy: 0.9799\n",
            "Epoch 4/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0809 - binary_accuracy: 0.9825\n",
            "Epoch 5/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0734 - binary_accuracy: 0.9845\n",
            "Epoch 6/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0690 - binary_accuracy: 0.9853\n",
            "Epoch 7/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0649 - binary_accuracy: 0.9861\n",
            "Epoch 8/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0612 - binary_accuracy: 0.9870\n",
            "Epoch 9/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0590 - binary_accuracy: 0.9875\n",
            "Epoch 10/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0562 - binary_accuracy: 0.9881\n",
            "Epoch 11/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0557 - binary_accuracy: 0.9883\n",
            "Epoch 12/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0546 - binary_accuracy: 0.9886\n",
            "Epoch 13/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0542 - binary_accuracy: 0.9888\n",
            "Epoch 14/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0534 - binary_accuracy: 0.9888\n",
            "Epoch 15/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0516 - binary_accuracy: 0.9893\n",
            "Epoch 16/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0519 - binary_accuracy: 0.9893\n",
            "Epoch 17/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0517 - binary_accuracy: 0.9896\n",
            "Epoch 18/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0503 - binary_accuracy: 0.9897\n",
            "Epoch 19/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0505 - binary_accuracy: 0.9898\n",
            "Epoch 20/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0495 - binary_accuracy: 0.9900\n",
            "Epoch 21/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0493 - binary_accuracy: 0.9901\n",
            "Epoch 22/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0494 - binary_accuracy: 0.9900\n",
            "Epoch 23/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0487 - binary_accuracy: 0.9903\n",
            "Epoch 24/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0489 - binary_accuracy: 0.9902\n",
            "Epoch 25/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0475 - binary_accuracy: 0.9903\n",
            "Epoch 26/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0475 - binary_accuracy: 0.9903\n",
            "Epoch 27/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0466 - binary_accuracy: 0.9906\n",
            "Epoch 28/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0467 - binary_accuracy: 0.9906\n",
            "Epoch 29/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0463 - binary_accuracy: 0.9905\n",
            "Epoch 30/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0462 - binary_accuracy: 0.9906\n",
            "Fold atual = 3\n",
            "RANDOM SEEDS RESET\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 44, 116, 32)       832       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 44, 116, 32)      128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 22, 58, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 22, 58, 64)        51264     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 22, 58, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 11, 29, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 20416)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20416)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1306688   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,359,233\n",
            "Trainable params: 1,359,041\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.2530 - binary_accuracy: 0.9088\n",
            "Epoch 2/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.1338 - binary_accuracy: 0.9674\n",
            "Epoch 3/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0995 - binary_accuracy: 0.9782\n",
            "Epoch 4/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0837 - binary_accuracy: 0.9823\n",
            "Epoch 5/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0741 - binary_accuracy: 0.9849\n",
            "Epoch 6/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0693 - binary_accuracy: 0.9859\n",
            "Epoch 7/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0650 - binary_accuracy: 0.9871\n",
            "Epoch 8/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0625 - binary_accuracy: 0.9877\n",
            "Epoch 9/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0613 - binary_accuracy: 0.9880\n",
            "Epoch 10/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0583 - binary_accuracy: 0.9887\n",
            "Epoch 11/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0568 - binary_accuracy: 0.9888\n",
            "Epoch 12/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0563 - binary_accuracy: 0.9892\n",
            "Epoch 13/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0550 - binary_accuracy: 0.9895\n",
            "Epoch 14/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0539 - binary_accuracy: 0.9896\n",
            "Epoch 15/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0526 - binary_accuracy: 0.9898\n",
            "Epoch 16/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0516 - binary_accuracy: 0.9900\n",
            "Epoch 17/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0520 - binary_accuracy: 0.9899\n",
            "Epoch 18/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0508 - binary_accuracy: 0.9903\n",
            "Epoch 19/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0506 - binary_accuracy: 0.9902\n",
            "Epoch 20/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0493 - binary_accuracy: 0.9906\n",
            "Epoch 21/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0493 - binary_accuracy: 0.9906\n",
            "Epoch 22/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0482 - binary_accuracy: 0.9907\n",
            "Epoch 23/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0492 - binary_accuracy: 0.9904\n",
            "Epoch 24/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0486 - binary_accuracy: 0.9905\n",
            "Epoch 25/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0480 - binary_accuracy: 0.9909\n",
            "Epoch 26/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0480 - binary_accuracy: 0.9908\n",
            "Epoch 27/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0478 - binary_accuracy: 0.9909\n",
            "Epoch 28/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0477 - binary_accuracy: 0.9909\n",
            "Epoch 29/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0472 - binary_accuracy: 0.9909\n",
            "Epoch 30/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0478 - binary_accuracy: 0.9910\n",
            "Fold atual = 4\n",
            "RANDOM SEEDS RESET\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 44, 116, 32)       832       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 44, 116, 32)      128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 22, 58, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 22, 58, 64)        51264     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 22, 58, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 11, 29, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 20416)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20416)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1306688   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,359,233\n",
            "Trainable params: 1,359,041\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.2134 - binary_accuracy: 0.9342\n",
            "Epoch 2/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.1191 - binary_accuracy: 0.9687\n",
            "Epoch 3/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0948 - binary_accuracy: 0.9777\n",
            "Epoch 4/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0849 - binary_accuracy: 0.9814\n",
            "Epoch 5/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0775 - binary_accuracy: 0.9832\n",
            "Epoch 6/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0715 - binary_accuracy: 0.9845\n",
            "Epoch 7/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0676 - binary_accuracy: 0.9851\n",
            "Epoch 8/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0640 - binary_accuracy: 0.9863\n",
            "Epoch 9/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0617 - binary_accuracy: 0.9866\n",
            "Epoch 10/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0600 - binary_accuracy: 0.9871\n",
            "Epoch 11/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0589 - binary_accuracy: 0.9873\n",
            "Epoch 12/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0576 - binary_accuracy: 0.9877\n",
            "Epoch 13/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0573 - binary_accuracy: 0.9878\n",
            "Epoch 14/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0563 - binary_accuracy: 0.9881\n",
            "Epoch 15/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0555 - binary_accuracy: 0.9881\n",
            "Epoch 16/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0552 - binary_accuracy: 0.9887\n",
            "Epoch 17/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0545 - binary_accuracy: 0.9887\n",
            "Epoch 18/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0534 - binary_accuracy: 0.9891\n",
            "Epoch 19/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0528 - binary_accuracy: 0.9893\n",
            "Epoch 20/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0524 - binary_accuracy: 0.9891\n",
            "Epoch 21/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0517 - binary_accuracy: 0.9895\n",
            "Epoch 22/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0513 - binary_accuracy: 0.9893\n",
            "Epoch 23/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0508 - binary_accuracy: 0.9894\n",
            "Epoch 24/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0505 - binary_accuracy: 0.9893\n",
            "Epoch 25/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0502 - binary_accuracy: 0.9893\n",
            "Epoch 26/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0499 - binary_accuracy: 0.9895\n",
            "Epoch 27/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0496 - binary_accuracy: 0.9896\n",
            "Epoch 28/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0493 - binary_accuracy: 0.9897\n",
            "Epoch 29/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0493 - binary_accuracy: 0.9896\n",
            "Epoch 30/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0483 - binary_accuracy: 0.9899\n",
            "Fold atual = 5\n",
            "RANDOM SEEDS RESET\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 44, 116, 32)       832       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 44, 116, 32)      128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 22, 58, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 22, 58, 64)        51264     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 22, 58, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 11, 29, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 20416)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20416)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1306688   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,359,233\n",
            "Trainable params: 1,359,041\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.2288 - binary_accuracy: 0.9262\n",
            "Epoch 2/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.1322 - binary_accuracy: 0.9667\n",
            "Epoch 3/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0954 - binary_accuracy: 0.9789\n",
            "Epoch 4/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0811 - binary_accuracy: 0.9823\n",
            "Epoch 5/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0736 - binary_accuracy: 0.9841\n",
            "Epoch 6/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0689 - binary_accuracy: 0.9854\n",
            "Epoch 7/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0663 - binary_accuracy: 0.9863\n",
            "Epoch 8/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0641 - binary_accuracy: 0.9871\n",
            "Epoch 9/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0617 - binary_accuracy: 0.9875\n",
            "Epoch 10/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0596 - binary_accuracy: 0.9881\n",
            "Epoch 11/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0583 - binary_accuracy: 0.9882\n",
            "Epoch 12/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0570 - binary_accuracy: 0.9884\n",
            "Epoch 13/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0550 - binary_accuracy: 0.9888\n",
            "Epoch 14/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0538 - binary_accuracy: 0.9891\n",
            "Epoch 15/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0530 - binary_accuracy: 0.9892\n",
            "Epoch 16/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0520 - binary_accuracy: 0.9891\n",
            "Epoch 17/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0519 - binary_accuracy: 0.9893\n",
            "Epoch 18/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0504 - binary_accuracy: 0.9896\n",
            "Epoch 19/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0505 - binary_accuracy: 0.9896\n",
            "Epoch 20/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0494 - binary_accuracy: 0.9897\n",
            "Epoch 21/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0491 - binary_accuracy: 0.9898\n",
            "Epoch 22/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0484 - binary_accuracy: 0.9900\n",
            "Epoch 23/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0484 - binary_accuracy: 0.9902\n",
            "Epoch 24/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0481 - binary_accuracy: 0.9902\n",
            "Epoch 25/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0469 - binary_accuracy: 0.9905\n",
            "Epoch 26/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0476 - binary_accuracy: 0.9902\n",
            "Epoch 27/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0466 - binary_accuracy: 0.9905\n",
            "Epoch 28/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0468 - binary_accuracy: 0.9904\n",
            "Epoch 29/30\n",
            "8041/8041 [==============================] - 86s 11ms/step - loss: 0.0463 - binary_accuracy: 0.9907\n",
            "Epoch 30/30\n",
            "8041/8041 [==============================] - 85s 11ms/step - loss: 0.0460 - binary_accuracy: 0.9907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics_df)"
      ],
      "metadata": {
        "id": "0fGsX-_ZPZza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "379b54a9-a14b-4e55-f3ce-dd7772e2fd16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   fold       acc      prec    recall        f1   roc_auc\n",
            "0     1  0.993284  0.995421  0.982579  0.988958  0.990293\n",
            "1     2  0.993883  0.982689  0.997587  0.990082  0.994918\n",
            "2     3  0.994917  0.987610  0.995886  0.991731  0.995188\n",
            "3     4  0.993945  0.984462  0.995937  0.990166  0.994502\n",
            "4     5  0.995546  0.992212  0.993245  0.992728  0.994903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0xPE2WGnTaJE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}